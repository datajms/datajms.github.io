<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Fairness on Trusted AI Ideas</title>
    <link>/tags/fairness/</link>
    <description>Recent content in Fairness on Trusted AI Ideas</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Feb 2023 12:16:19 +0100</lastBuildDate>
    <atom:link href="/tags/fairness/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Exploring ChatGPT guardails: from protected to forgotten countries (Part 1)</title>
      <link>/post/chatgpt_country_guardrails_study/</link>
      <pubDate>Fri, 24 Feb 2023 12:16:19 +0100</pubDate>
      <guid>/post/chatgpt_country_guardrails_study/</guid>
      <description>&lt;p&gt;&lt;strong&gt;OpenAI ChatGPT has built guardrails&lt;/strong&gt; on limiting the generation of negative content.&#xA;How do these guardrails behave for countries?&#xA;Spoiler: there are some &lt;strong&gt;gaps and disparities&lt;/strong&gt; in ChatGPT safety mechanisms.&#xA;Based on 24100 ChatGPT queries, this blog post is an exploration of ChatGPT responses when prompted to generate negative content about a country.&lt;/p&gt;&#xA;&lt;p&gt;If you are in a hurry, go and see the &lt;a href=&#34;#4-results&#34;&gt;early results&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-context-chatgpt-guardrails-and-harmful-content-prevention&#34;&gt;1. Context: ChatGPT guardrails and harmful content prevention.&lt;/h2&gt;&#xA;&lt;h3 id=&#34;11-openai-principles-and-methodology&#34;&gt;1.1. OpenAI Principles and Methodology&lt;/h3&gt;&#xA;&lt;p&gt;ChatGPT has been developed following a methodology based on Human Feedbacks (RLHF).&#xA;The main goal is preventing the AI-powered assistant to create inflammatory, dangerous, politically-oriented, censorship-heavy content&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&#xA;Defining such choices and thresholds relies on high-level principles, that OpenAI made partially public in a &lt;a href=&#34;https://cdn.openai.com/snapshot-of-chatgpt-model-behavior-guidelines.pdf&#34;&gt;3-page document of Guideline Instructions&lt;/a&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
