<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ideas on Data Science &amp; AI Ideas</title>
    <link>/tags/ideas/</link>
    <description>Recent content in ideas on Data Science &amp; AI Ideas</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Jun 2020 10:00:12 +0200</lastBuildDate>
    
	<atom:link href="/tags/ideas/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Death sentences and race-ethnicity</title>
      <link>/post/fairness_justice_death_sentence/</link>
      <pubDate>Wed, 03 Jun 2020 10:00:12 +0200</pubDate>
      
      <guid>/post/fairness_justice_death_sentence/</guid>
      <description>This post will present and explain a situation where Black Lives Mattered less. In Oklahoma, from 1990 to 2012, 143 offenders were sentenced to death. In 2017, Pierce et al.1 collected and analyzed the homicide data (4668 offenders) and the death sentences. It shows that there are several race/ethnicity effects involved in the death sentences outcomes. The paper contains all details. Terminology used (&amp;ldquo;nonwhite&amp;rdquo;, &amp;ldquo;race&amp;rdquo;) comes from the paper. I don&amp;rsquo;t like the &amp;ldquo;nonwhite&amp;rdquo; term, but I cannot easily replace it each time with Black, Hispanic, Native American and Asian.</description>
    </item>
    
    <item>
      <title>Do you know the 4 types of additive Variable Importances?</title>
      <link>/post/variable_importance_feature_attribution/</link>
      <pubDate>Sat, 16 May 2020 15:36:11 +0200</pubDate>
      
      <guid>/post/variable_importance_feature_attribution/</guid>
      <description>Facing complex models, both computer simulation and machine learning practitioners have pursued similar objectives: to see how results could be broken down and linked to the inputs. Whether it is called Sensitivity Analysis or Variable Importance in the context of explainable AI, some of their methods share an important component: the Shapley values.
This article presents a structured 2 by 2 matrix to think about Variable Importances in terms of their goals.</description>
    </item>
    
  </channel>
</rss>