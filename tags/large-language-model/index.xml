<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>large language model on Data Science &amp; AI Ideas</title>
    <link>/tags/large-language-model/</link>
    <description>Recent content in large language model on Data Science &amp; AI Ideas</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Feb 2023 12:16:19 +0100</lastBuildDate>
    
	<atom:link href="/tags/large-language-model/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Exploring ChatGPT guardails: from protected to forgotten countries (Part 1)</title>
      <link>/post/chatgpt_country_guardrails_study/</link>
      <pubDate>Fri, 24 Feb 2023 12:16:19 +0100</pubDate>
      
      <guid>/post/chatgpt_country_guardrails_study/</guid>
      <description>OpenAI ChatGPT has built guardrails on limiting the generation of negative content. How do these guardrails behave for countries? Spoiler: there are some gaps and disparities in ChatGPT safety mechanisms. Based on 24100 ChatGPT queries, this blog post is an exploration of ChatGPT responses when prompted to generate negative content about a country.
If you are in a hurry, go and see the early results.
1. Context: ChatGPT guardrails and harmful content prevention.</description>
    </item>
    
  </channel>
</rss>